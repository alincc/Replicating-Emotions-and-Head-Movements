{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#######################################################################################################\n",
      "# Author: Jan Ondras\n",
      "# Institution: University of Cambridge\n",
      "# Project: Replicating Human Facial Emotions and Head Movements on a Robot Avatar (Part II Project)\n",
      "# Duration: October 2016 - May 2017\n",
      "####################################################################################################### \n",
      "# Final MLP training using tuned parameters\n",
      "# Produce weights for real-time inference\n",
      "# This is for selected 4 classes only!\n",
      "#######################################################################################################\n",
      "\n",
      "import time\n",
      "import numpy as np \n",
      "from sklearn.neural_network import MLPClassifier\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "outWeightsFile = \"./weights.npz\"\n",
      "classes = ['neutral', 'disgust', 'happiness', 'surprise']\n",
      "\n",
      "# Hyperparameters:\n",
      "WINDOW = 5 # \n",
      "hls = (4,) # \n",
      "alpha = 1e-3 # \n",
      "chosenRandomSeed = 36 #\n",
      "#strategy = 'concat'\n",
      "strategy = 'avg'\n",
      "\n",
      "examples = np.genfromtxt('./dataCKplus/examples/ex7AU4' + strategy + 'W' + str(WINDOW) + '.dat')\n",
      "# Use all data for training\n",
      "X_train = examples[:, :-1]\n",
      "y_train = examples[:, -1]\n",
      "\n",
      "clf = MLPClassifier(solver='lbfgs', alpha=alpha, hidden_layer_sizes=hls, random_state=chosenRandomSeed)\n",
      "clf.fit(X_train, y_train)\n",
      "\n",
      "# Parameters for export\n",
      "w1 = clf.coefs_[0]\n",
      "w2 = clf.coefs_[1]\n",
      "b1 = clf.intercepts_[0]\n",
      "b2 = clf.intercepts_[1]\n",
      "\n",
      "# Save weights\n",
      "np.savez(outWeightsFile, w1=w1, b1=b1, w2=w2, b2=b2, WINDOW=WINDOW, strategy=strategy)\n",
      "# Read:\n",
      "# data = np.load(outWeightsFile)\n",
      "# data['w1']\n",
      "# data.close()\n",
      "\n",
      "#######################################################################################################\n",
      "# Below is manual prediction using these weights (just for testing)\n",
      "\n",
      "# print [coef.shape for coef in clf.coefs_]\n",
      "# print [i.shape for i in clf.intercepts_]\n",
      "# print clf.coefs_[0]\n",
      "# print clf.coefs_[1]\n",
      "# print clf.intercepts_[0]\n",
      "# print clf.intercepts_[1]\n",
      "\n",
      "print X_train[0]\n",
      "print \"Predict:\"\n",
      "print \"Class: \", clf.predict([X_train[0]])[0]\n",
      "print \"Probabilities: \", clf.predict_proba([X_train[0]])[0]\n",
      "print \"Compare with manual:\"\n",
      "\n",
      "# f = np.dot(w2.T, np.tanh(np.dot(w1.T, X_test[0]) + b1)) + b2\t\t# equivalent, tanh activation\n",
      "# f = np.dot(np.tanh(np.dot(X_train[0], w1) + b1), w2) + b2\n",
      "\n",
      "# Forward pass\n",
      "f = np.dot(np.maximum(np.zeros(len(b1)), np.dot(X_train[0], w1) + b1), w2) + b2 # relu activation\n",
      "#print f\n",
      "# Softmax:\n",
      "s = np.exp(f) / np.sum(np.exp(f), axis=0)\n",
      "print \"Softmax prob.: \", s\n",
      "print \"Class: \", np.argmax(s)\n",
      "\n",
      "# Just test for all\n",
      "for x in X_train:\n",
      "\tf = np.dot(np.maximum(np.zeros(len(b1)), np.dot(x, w1) + b1), w2) + b2\n",
      "\ts = np.exp(f) / np.sum(np.exp(f), axis=0)\n",
      "\tif np.argmax(s) != clf.predict([x])[0]:\n",
      "\t\tprint \"Problem !\"\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.   0.2  0.6  0.   0.2  0.   0. ]\n",
        "Predict:\n",
        "Class:  1.0\n",
        "Probabilities:  [  3.68956181e-02   9.63098293e-01   1.07772811e-06   5.01169318e-06]\n",
        "Compare with manual:\n",
        "Softmax prob.:  [  3.68956181e-02   9.63098293e-01   1.07772811e-06   5.01169318e-06]\n",
        "Class:  1\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}