{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#######################################################################################################\n",
      "# Author: Jan Ondras\n",
      "# Institution: University of Cambridge\n",
      "# Project: Replicating Human Facial Emotions and Head Movements on a Robot Avatar (Part II Project)\n",
      "# Duration: October 2016 - May 2017\n",
      "####################################################################################################### \n",
      "# Cross-validate and tune hyperparameters\n",
      "# This uses crossvalidation on all the data and plots validation curves.\n",
      "# Tune hyperparameters in 2 phases\n",
      "# Use ONLY 4 classes, well separated examples \"...ex7AU4...\" are used\n",
      "'''\n",
      "1.) plot heatmap of train/Validation accuracy(&std) against window W and hidden layer size (hls) => 4 heatmaps\n",
      "    => tune architecture and feature representation\n",
      "2.) for chosen W and hls, crossvalidate regularisation alpha\n",
      "3.) plot confusion matrix sum over 5 cv folds\n",
      "\n",
      "Firstly done with random_state=0\n",
      "Then improved to try 50 different randomSeed [0,49]\n",
      "'''\n",
      "#######################################################################################################\n",
      "import time\n",
      "import numpy as np \n",
      "#from collections import Counter\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "#from sklearn.model_selection import GridSearchCV\n",
      "#from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.model_selection import validation_curve\n",
      "from sklearn.model_selection import learning_curve\n",
      "from sklearn.model_selection import StratifiedKFold\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "# 1.)\n",
      "\n",
      "#strategy = 'concat'\n",
      "strategy = 'avg'\n",
      "windows = range(1, 6 + 1)\n",
      "hls = range(1, 30)\n",
      "K = 5\n",
      "numRandomSeeds = 50\n",
      "# number of folds, Stratified K-fold crossvalidator is used, later use leave one subject out\n",
      "# K = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "# for train_index, test_index in K.split(X, y):\n",
      "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "#     X_train, X_test = X[train_index], X[test_index]\n",
      "#     y_train, y_test = y[train_index], y[test_index]\n",
      "\n",
      "train_scores_means = np.zeros((numRandomSeeds, len(windows), len(hls)))\n",
      "train_scores_stds = np.zeros((numRandomSeeds, len(windows), len(hls)))\n",
      "test_scores_means = np.zeros((numRandomSeeds, len(windows), len(hls)))\n",
      "test_scores_stds = np.zeros((numRandomSeeds, len(windows), len(hls)))\n",
      "\n",
      "best_train_scores_means = np.zeros((len(windows), len(hls)))\n",
      "best_train_scores_stds = np.zeros((len(windows), len(hls)))\n",
      "best_test_scores_means = np.zeros((len(windows), len(hls)))\n",
      "best_test_scores_stds = np.zeros((len(windows), len(hls)))\n",
      "\n",
      "for randomSeed in range(numRandomSeeds):\n",
      "    start = time.time()\n",
      "    # For every window size\n",
      "    for WINDOW in windows:\n",
      "        \n",
      "        examples = np.genfromtxt('./dataCKplus/examples/ex7AU4' + strategy + 'W' + str(WINDOW) + '.dat')\n",
      "        X = examples[:, :-1]\n",
      "        y = examples[:, -1]\n",
      "        \n",
      "        # Crossvalidate!\n",
      "        train_scores, test_scores = validation_curve(\n",
      "            MLPClassifier(solver='lbfgs', random_state=randomSeed), X, y, \n",
      "            param_name=\"hidden_layer_sizes\", param_range=[(x, ) for x in hls],\n",
      "            cv=K, scoring=\"accuracy\", n_jobs=-1)\n",
      "        \n",
      "        # Log data\n",
      "        train_scores_means[randomSeed][WINDOW - 1] = np.mean(train_scores, axis=1)\n",
      "        train_scores_stds[randomSeed][WINDOW - 1] = np.std(train_scores, axis=1)\n",
      "        test_scores_means[randomSeed][WINDOW - 1] = np.mean(test_scores, axis=1)\n",
      "        test_scores_stds[randomSeed][WINDOW - 1] = np.std(test_scores, axis=1)\n",
      "    print \"Time: %d sec\" %(time.time() - start)\n",
      "\n",
      "bestRandomSeeds = np.argmax(test_scores_means, axis=0)\n",
      "print bestRandomSeeds\n",
      "for w in windows:\n",
      "    for h in hls:\n",
      "        best_train_scores_means[w - 1, h - 1] = train_scores_means[bestRandomSeeds[w - 1, h - 1]][w - 1, h - 1]\n",
      "        best_train_scores_stds[w - 1, h - 1] = train_scores_stds[bestRandomSeeds[w - 1, h - 1]][w - 1, h - 1]\n",
      "        best_test_scores_means[w - 1, h - 1] = test_scores_means[bestRandomSeeds[w - 1, h - 1]][w - 1, h - 1]\n",
      "        best_test_scores_stds[w - 1, h - 1] = test_scores_stds[bestRandomSeeds[w - 1, h - 1]][w - 1, h - 1]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 17 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 25 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 26 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 24 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 23 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 23 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 27 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 26 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 31 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 34 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 28 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 27 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 28 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 28 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 28 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 32 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 32 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 29 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 29 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 29 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 29 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 36 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 40 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 29 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 29 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 31 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 29 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 31 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 33 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 31 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 33 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 33 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 33 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 31 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 32 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 32 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 32 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 32 sec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 30 sec\n",
        "[[11  6 44 35 40 34 42 39 19 14 20 14  0  9 20  3  3 49 47 31 34  3 11 11\n",
        "   6 31 36 37 13]\n",
        " [32 39 22 43 43 38 17 41  7 35 13 31 37 25 30 34 29 46 31 32 22 33 33 27\n",
        "  32 17 47  1 38]\n",
        " [41 40 43  6 10 21 11  8 33 23 10 31 10 29  4  0 25  3 10 48 41 47  3 26\n",
        "  31  4  9 22 39]\n",
        " [19  6 49 44  4 17 27 26 34 28 32 12 25 13 36  6  8  3 44 20 32 22 26 32\n",
        "  20  8 36 30 18]\n",
        " [19 22 49 36 33 17 31 46 44 15 13 13 15 44 29  7 16  3 47 31  2  7 19 15\n",
        "  44 37 48 13 24]\n",
        " [18 13 15 33 27 17 45 33 40 47 15 30  5 45 32 15  3 23 41 15 15 12 19 40\n",
        "  13 39 17 33 13]]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to save the results\n",
      "# print best_train_scores_means\n",
      "# print best_train_scores_stds\n",
      "# print best_test_scores_means\n",
      "# print best_test_scores_stds\n",
      "\n",
      "# Just for me to see\n",
      "fig = plt.figure()\n",
      "lw = 1\n",
      "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
      "for WINDOW in windows: # [5]\n",
      "    plt.plot(hls, best_train_scores_means[WINDOW - 1], '-o', color=colors[WINDOW - 1], label='Window ' + str(WINDOW))\n",
      "    #plt.errorbar(hls, best_train_scores_means[WINDOW - 1], yerr=best_train_scores_stds[WINDOW - 1], fmt='-o', color=colors[WINDOW - 1], label='Window ' + str(WINDOW))\n",
      "#     plt.fill_between(hls, best_train_scores_means[WINDOW - 1] - best_train_scores_stds[WINDOW - 1],\n",
      "#                  best_train_scores_means[WINDOW - 1] + best_train_scores_stds[WINDOW - 1], \n",
      "#                  alpha=0.05, color=colors[WINDOW - 1], lw=lw)\n",
      "    #plt.errorbar(hls, best_test_scores_means[WINDOW - 1], yerr=best_test_scores_stds[WINDOW - 1], color=colors[WINDOW - 1])\n",
      "    plt.plot(hls, best_test_scores_means[WINDOW - 1], color=colors[WINDOW - 1]) # label='Window ' + str(WINDOW)\n",
      "#     plt.fill_between(hls, best_test_scores_means[WINDOW - 1] - best_test_scores_stds[WINDOW - 1],\n",
      "#                 best_test_scores_means[WINDOW - 1] + best_test_scores_stds[WINDOW - 1], \n",
      "#                 alpha=0.05, color=colors[WINDOW - 1], lw=lw)\n",
      "    \n",
      "plt.title('Training & validation accuracy, strategy = ' + strategy)\n",
      "plt.xlabel('Hidden layer size')\n",
      "plt.ylabel('Accuracy')\n",
      "plt.ylim([0.75, 0.96])\n",
      "plt.legend(loc='center right')\n",
      "\n",
      "ax = fig.add_subplot(1,1,1)                                                                                           \n",
      "ax.set_xticks(hls, minor=True)                                                       \n",
      "ax.set_xticks(np.arange(0, 30, 5) , minor=False)                                                                                   \n",
      "ax.grid(which='minor', alpha=0.3, ls='dotted')\n",
      "plt.show()\n",
      "\n",
      "# Check max validation score\n",
      "W_opt = np.argmax(best_test_scores_means) // len(hls) # = optimal W-1\n",
      "hls_opt = np.argmax(best_test_scores_means) % len(hls)# = optimal hls-1\n",
      "print W_opt\n",
      "print hls_opt\n",
      "print bestRandomSeeds[W_opt, hls_opt] # = optimal random seed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n",
        "3\n",
        "36\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot 4 heatmaps\n",
      "plt.figure()\n",
      "X, Y = np.meshgrid(hls, windows)\n",
      "levels = np.linspace(0.72, 0.96, num=30)\n",
      "levelsSTD = np.linspace(0.003, 0.085, num=30)\n",
      "\n",
      "plt.subplot(2, 2, 1)\n",
      "#cp = plt.contourf(X, Y, train_scores_means, 10, vmin=0.0, vmax=1.0)\n",
      "cp = plt.contourf(X, Y, best_train_scores_means, levels=levels)\n",
      "plt.colorbar(cp)\n",
      "plt.title('Training accuracy, strategy = ' + strategy)\n",
      "plt.xlabel('Hidden layer size')\n",
      "plt.ylabel('Window size')\n",
      "\n",
      "plt.subplot(2, 2, 2)\n",
      "cp = plt.contourf(X, Y, best_test_scores_means, levels=levels)\n",
      "plt.colorbar(cp)\n",
      "plt.title('Validation accuracy, strategy = ' + strategy)\n",
      "plt.xlabel('Hidden layer size')\n",
      "plt.ylabel('Window size')\n",
      "\n",
      "plt.subplot(2, 2, 3)\n",
      "cp = plt.contourf(X, Y, best_train_scores_stds, levels=levelsSTD)\n",
      "plt.colorbar(cp)\n",
      "plt.title('Training STD, strategy = ' + strategy)\n",
      "plt.xlabel('Hidden layer size')\n",
      "plt.ylabel('Window size')\n",
      "\n",
      "plt.subplot(2, 2, 4)\n",
      "cp = plt.contourf(X, Y, best_test_scores_stds, levels=levelsSTD)\n",
      "plt.colorbar(cp)\n",
      "plt.title('Validation STD, strategy = ' + strategy)\n",
      "plt.xlabel('Hidden layer size')\n",
      "plt.ylabel('Window size')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import numpy as np \n",
      "#from collections import Counter\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "#from sklearn.model_selection import GridSearchCV\n",
      "#from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.model_selection import validation_curve\n",
      "from sklearn.model_selection import learning_curve\n",
      "from sklearn.model_selection import StratifiedKFold\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# 2.) part - tune alpha - regularisation\n",
      "# chosen parameters\n",
      "WINDOW = 5\n",
      "hls = (4,)\n",
      "chosenRandomSeed = 36 #\n",
      "alphas = np.logspace(-6, 2, 1000)\n",
      "#strategy = 'concat'\n",
      "strategy = 'avg'\n",
      "K = 5\n",
      "\n",
      "examples = np.genfromtxt('./dataCKplus/examples/ex7AU4' + strategy + 'W' + str(WINDOW) + '.dat')\n",
      "X = examples[:, :-1]\n",
      "y = examples[:, -1]\n",
      "\n",
      "start = time.time()\n",
      "train_scores, test_scores = validation_curve(\n",
      "    MLPClassifier(solver='lbfgs', random_state=chosenRandomSeed, hidden_layer_sizes=hls), X, y, \n",
      "    param_name='alpha', param_range=alphas,\n",
      "    cv=K, scoring='accuracy', n_jobs=-1)\n",
      "print \"Time: \"\n",
      "print time.time() - start\n",
      "\n",
      "train_scores_mean = np.mean(train_scores, axis=1)\n",
      "train_scores_std = np.std(train_scores, axis=1)\n",
      "test_scores_mean = np.mean(test_scores, axis=1)\n",
      "test_scores_std = np.std(test_scores, axis=1)\n",
      "\n",
      "plt.figure()\n",
      "plt.title(\"Validation Curve, strategy = \" + strategy)\n",
      "plt.xlabel(\"alpha - regularisation\")\n",
      "plt.ylabel(\"Score\")\n",
      "plt.xscale('log')\n",
      "lw = 2\n",
      "plt.plot(alphas, train_scores_mean, label=\"Training score\",\n",
      "             color=\"darkorange\", lw=lw)\n",
      "plt.fill_between(alphas, train_scores_mean - train_scores_std,\n",
      "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
      "                 color=\"darkorange\", lw=lw)\n",
      "plt.plot(alphas, test_scores_mean, label=\"Testing score\",\n",
      "             color=\"navy\", lw=lw)\n",
      "plt.fill_between(alphas, test_scores_mean - test_scores_std,\n",
      "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
      "                 color=\"navy\", lw=lw)\n",
      "plt.ylim([0.55, 0.92])\n",
      "plt.legend(loc=\"best\")\n",
      "plt.grid()\n",
      "plt.show()\n",
      "\n",
      "print alphas[np.argmax(test_scores_mean)] # optimal alpha = 0.000970480887738"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: \n",
        "156.086325169\n",
        "0.000970480887738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import numpy as np \n",
      "#from collections import Counter\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "#from sklearn.model_selection import GridSearchCV\n",
      "#from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.model_selection import validation_curve\n",
      "from sklearn.model_selection import learning_curve\n",
      "from sklearn.model_selection import StratifiedKFold\n",
      "from sklearn.metrics import accuracy_score\n",
      "import itertools\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# 3.) plot sum of confusion matrices over all folds\n",
      "WINDOW = 5\n",
      "hls = (4,)\n",
      "alpha = 1e-3 # alpha chosen: 1e-1\n",
      "chosenRandomSeed = 36 #\n",
      "#strategy = 'concat'\n",
      "strategy = 'avg'\n",
      "\n",
      "classes = ['neutral', 'disgust', 'happiness', 'surprise']\n",
      "K = 5\n",
      "skf = StratifiedKFold(n_splits=K)\n",
      "confusionMatSum = np.zeros((len(classes), len(classes)))\n",
      "normalizeCM = True\n",
      "train_scores = []\n",
      "test_scores = []\n",
      "\n",
      "examples = np.genfromtxt('./dataCKplus/examples/ex7AU4' + strategy + 'W' + str(WINDOW) + '.dat')\n",
      "X = examples[:, :-1]\n",
      "y = examples[:, -1]\n",
      "\n",
      "for train_index, test_index in skf.split(X, y):\n",
      "    mlp = MLPClassifier(solver='lbfgs', random_state=chosenRandomSeed, hidden_layer_sizes=hls, alpha=alpha)\n",
      "    mlp.fit(X[train_index], y[train_index])\n",
      "    y_pred = mlp.predict(X[test_index])\n",
      "    cm = confusion_matrix(y[test_index], y_pred)\n",
      "    #print cm\n",
      "    confusionMatSum = confusionMatSum + cm\n",
      "    # Log accuracy scores\n",
      "    train_scores.append(accuracy_score(y[train_index], mlp.predict(X[train_index])))\n",
      "    test_scores.append(accuracy_score(y[test_index], y_pred))\n",
      "\n",
      "# Print results: training & test accuracy + stds\n",
      "train_score_mean = np.mean(train_scores)\n",
      "train_score_std = np.std(train_scores)\n",
      "test_score_mean = np.mean(test_scores)\n",
      "test_score_std = np.std(test_scores)\n",
      "print \"Training score: %f +/- %f\" %(train_score_mean, train_score_std)\n",
      "print \"Validation score: %f +/- %f\" %(test_score_mean, test_score_std)\n",
      "\n",
      "# show cm\n",
      "plt.figure()\n",
      "if normalizeCM:\n",
      "    confusionMatSum = confusionMatSum.astype('float') / confusionMatSum.sum(axis=1)[:, np.newaxis]\n",
      "    print(\"Normalized confusion matrix\")\n",
      "    plt.title('Normalized confusion matrix after cross-validation, strategy = ' + strategy)\n",
      "else:\n",
      "    plt.title('Confusion matrix after cross-validation, strategy = ' + strategy)\n",
      "print confusionMatSum\n",
      "plt.imshow(confusionMatSum, interpolation='nearest', cmap=plt.cm.Blues)\n",
      "plt.colorbar()\n",
      "tick_marks = np.arange(len(classes))\n",
      "plt.xticks(tick_marks, classes, rotation=45)\n",
      "plt.yticks(tick_marks, classes)\n",
      "# if normalizeCM:\n",
      "#     confusionMatSum = confusionMatSum.astype('float') / confusionMatSum.sum(axis=1)[:, np.newaxis]\n",
      "#     print(\"Normalized confusion matrix\")\n",
      "# print confusionMatSum\n",
      "thresh = confusionMatSum.max() / 2.\n",
      "for i, j in itertools.product(range(confusionMatSum.shape[0]), range(confusionMatSum.shape[1])):\n",
      "    if normalizeCM:\n",
      "        plt.text(j, i, '%.3f' % (confusionMatSum[i, j]), horizontalalignment=\"center\", color=\"white\" if confusionMatSum[i, j] > thresh else \"black\")\t# fix text color\n",
      "    else:\n",
      "        plt.text(j, i, int(confusionMatSum[i, j]), horizontalalignment=\"center\", color=\"white\" if confusionMatSum[i, j] > thresh else \"black\")\t# fix text color\n",
      "plt.tight_layout()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training score: 0.866532 +/- 0.015780\n",
        "Testing score: 0.833719 +/- 0.045175\n",
        "Normalized confusion matrix\n",
        "[[ 0.74698795  0.08433735  0.13253012  0.03614458]\n",
        " [ 0.11864407  0.83050847  0.05084746  0.        ]\n",
        " [ 0.04347826  0.11594203  0.84057971  0.        ]\n",
        " [ 0.07228916  0.          0.01204819  0.91566265]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}